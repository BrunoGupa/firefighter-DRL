{
 "cells": [
  {
   "cell_type": "raw",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_cellular_automata as gymca\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:03:53.088374458Z",
     "start_time": "2023-06-13T21:03:51.271354690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trees:  38\n",
      "Total trees:  38\n"
     ]
    }
   ],
   "source": [
    "from Solver_Firefighter.reward_wrappers import NumTreesRewardStepOne\n",
    "import numpy as np\n",
    "\n",
    "SQUARE_SHAPE = 10\n",
    "T_MOVE = 0.025\n",
    "T_SHOOT = 0.1\n",
    "T_ANY = 0.025\n",
    "POS_BULL = [SQUARE_SHAPE-1, SQUARE_SHAPE-1]\n",
    "BULL_POS = f'{SQUARE_SHAPE-1}.{SQUARE_SHAPE-1}'\n",
    "POS_FIRE = (5,0)\n",
    "\n",
    "\n",
    "ProtoEnv = gymca.prototypes[1]\n",
    "env = ProtoEnv(nrows=SQUARE_SHAPE,\n",
    "               ncols=SQUARE_SHAPE,\n",
    "               pos_bull=POS_BULL,\n",
    "               pos_fire=POS_FIRE,\n",
    "               t_move=T_MOVE,\n",
    "               t_shoot=T_SHOOT,\n",
    "               t_any=T_ANY)\n",
    "\n",
    "env.reset()\n",
    "env.render()\n",
    "obs = env.reset()\n",
    "env = NumTreesRewardStepOne(env)\n",
    "#env.render()\n",
    "total_reward = 0.0\n",
    "done = False\n",
    "step = 0\n",
    "threshold = 30\n",
    "\n",
    "env.render()\n",
    "print(\"Total trees: \", np.sum(np.where(env.grid == 3, 1, 0)))\n",
    "total_loss = 0\n",
    "#env.observation_space.sample()\n",
    "\n",
    "done = True\n",
    "\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()  # Your agent goes here!\n",
    "    obs, reward, done, info = env.step([4,1])\n",
    "\n",
    "    env.render()\n",
    "    if reward != 0:\n",
    "        total_loss += reward\n",
    "        print(\"reward\", reward, \"total loss\", total_loss)\n",
    "\n",
    "\n",
    "env.render()\n",
    "print(\"Total trees: \", np.sum(np.where(env.grid == 3, 1, 0)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:03:56.234656313Z",
     "start_time": "2023-06-13T21:03:53.737041723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C, SAC, PPO, TD3, DQN\n",
    "import os\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:03:56.950192514Z",
     "start_time": "2023-06-13T21:03:56.945020591Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_dir = \"avatar-graph_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:03:57.747605997Z",
     "start_time": "2023-06-13T21:03:57.744750992Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# We going to save the total burnt nodes.\n",
    "RL_objective = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:04:02.802253836Z",
     "start_time": "2023-06-13T21:04:02.796466619Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avatar-fire-master-0-a\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'avatar-graph_models/avatar-fire-master-0-a.zip.zip'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_22667/2252267664.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[0menv_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmake_env\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mProtoEnv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparameters\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Get the environment creation function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m         \u001B[0menv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Create the environment instance\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m         \u001B[0mloaded_model\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPPO\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msave_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrun_name\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\".zip\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Load the trained model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     62\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mobs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/base_class.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001B[0m\n\u001B[1;32m    657\u001B[0m             \u001B[0mget_system_info\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    658\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 659\u001B[0;31m         data, params, pytorch_variables = load_from_zip_file(\n\u001B[0m\u001B[1;32m    660\u001B[0m             \u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    661\u001B[0m             \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/save_util.py\u001B[0m in \u001B[0;36mload_from_zip_file\u001B[0;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001B[0m\n\u001B[1;32m    388\u001B[0m         \u001B[0;32mand\u001B[0m \u001B[0mdict\u001B[0m \u001B[0mof\u001B[0m \u001B[0mpytorch\u001B[0m \u001B[0mvariables\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    389\u001B[0m     \"\"\"\n\u001B[0;32m--> 390\u001B[0;31m     \u001B[0mload_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopen_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mload_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuffix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"zip\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    391\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    392\u001B[0m     \u001B[0;31m# set device to cpu if cuda is not available\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/functools.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    875\u001B[0m                             '1 positional argument')\n\u001B[1;32m    876\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 877\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mdispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    878\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m     \u001B[0mfuncname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'__name__'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'singledispatch function'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/save_util.py\u001B[0m in \u001B[0;36mopen_path_str\u001B[0;34m(path, mode, verbose, suffix)\u001B[0m\n\u001B[1;32m    232\u001B[0m     \u001B[0;34m:\u001B[0m\u001B[0;32mreturn\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    233\u001B[0m     \"\"\"\n\u001B[0;32m--> 234\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mopen_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpathlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuffix\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    235\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    236\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/functools.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    875\u001B[0m                             '1 positional argument')\n\u001B[1;32m    876\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 877\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mdispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    878\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m     \u001B[0mfuncname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'__name__'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'singledispatch function'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/save_util.py\u001B[0m in \u001B[0;36mopen_path_pathlib\u001B[0;34m(path, mode, verbose, suffix)\u001B[0m\n\u001B[1;32m    284\u001B[0m     \u001B[0;31m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    285\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 286\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mopen_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuffix\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    287\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/functools.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    875\u001B[0m                             '1 positional argument')\n\u001B[1;32m    876\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 877\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mdispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__class__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    878\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m     \u001B[0mfuncname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'__name__'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'singledispatch function'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/save_util.py\u001B[0m in \u001B[0;36mopen_path_pathlib\u001B[0;34m(path, mode, verbose, suffix)\u001B[0m\n\u001B[1;32m    264\u001B[0m                 \u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuffix\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnewpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    265\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 266\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    267\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/save_util.py\u001B[0m in \u001B[0;36mopen_path_pathlib\u001B[0;34m(path, mode, verbose, suffix)\u001B[0m\n\u001B[1;32m    256\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    257\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 258\u001B[0;31m             \u001B[0mpath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    259\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mFileNotFoundError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    260\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0msuffix\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0msuffix\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/pathlib.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(self, mode, buffering, encoding, errors, newline)\u001B[0m\n\u001B[1;32m   1250\u001B[0m         \u001B[0mthe\u001B[0m \u001B[0mbuilt\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;32min\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0mfunction\u001B[0m \u001B[0mdoes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1251\u001B[0m         \"\"\"\n\u001B[0;32m-> 1252\u001B[0;31m         return io.open(self, mode, buffering, encoding, errors, newline,\n\u001B[0m\u001B[1;32m   1253\u001B[0m                        opener=self._opener)\n\u001B[1;32m   1254\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/pathlib.py\u001B[0m in \u001B[0;36m_opener\u001B[0;34m(self, name, flags, mode)\u001B[0m\n\u001B[1;32m   1118\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_opener\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0o666\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1119\u001B[0m         \u001B[0;31m# A stub for the opener argument to built-in open()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1120\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_accessor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1121\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1122\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_raw_open\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0o777\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'avatar-graph_models/avatar-fire-master-0-a.zip.zip'"
     ]
    }
   ],
   "source": [
    "# For loop over all models\n",
    "import imageio\n",
    "from stock_envs import make_env\n",
    "\n",
    "ESSAYS = 2\n",
    "\n",
    "\n",
    "MODEL = PPO\n",
    "NAME_MODEL = 'PPO'\n",
    "TOTAL_PROCS = 8\n",
    "TRAIN_STEPS = 1000#6e6\n",
    "STEPS_TRESH = int(1000)\n",
    "ENV_SEED = 100\n",
    "NAME_REWARD = 'NumTreesRewardStepOne'\n",
    "OBS_WRAP = 'ObservationOneHotWrapper_dict_box'\n",
    "POLICY_TYPE = 'MultiInputPolicy'\n",
    "\n",
    "\n",
    "move_values = {\n",
    "    0: {\"T_MOVE\": 0.025, \"T_SHOOT\": 0.1, \"T_ANY\": 0.025},\n",
    "    1: {\"T_MOVE\": 0.05, \"T_SHOOT\": 0.3, \"T_ANY\": 0.05},\n",
    "    2: {\"T_MOVE\": 0.1, \"T_SHOOT\": 0.5, \"T_ANY\": 0.05},\n",
    "    3: {\"T_MOVE\": 0.5, \"T_SHOOT\": 0.5, \"T_ANY\": 0.05},\n",
    "    4: {\"T_MOVE\": 0.1, \"T_SHOOT\": 0.15, \"T_ANY\": 0.03, \"D\": [4]},\n",
    "    5: {\"T_MOVE\": 0.2, \"T_SHOOT\": 0.025, \"T_ANY\": 0.025, \"D\": [5]},\n",
    "    6: {\"T_MOVE\": 0.3, \"T_SHOOT\": 0.1, \"T_ANY\": 0.025, \"D\": [3]},\n",
    "    7: {\"T_MOVE\": 0.4, \"T_SHOOT\": 0.05, \"T_ANY\": 0.05, \"D\": [3]},\n",
    "}\n",
    "\n",
    "for instance_value in range(8):\n",
    "    T_MOVE = move_values[instance_value][\"T_MOVE\"]\n",
    "    T_SHOOT = move_values[instance_value][\"T_SHOOT\"]\n",
    "    T_ANY = move_values[instance_value][\"T_ANY\"]\n",
    "\n",
    "    for POS_FIRE in [(5, 0), (4, 5)]:\n",
    "\n",
    "        parameters = {\n",
    "            'nrows': SQUARE_SHAPE,\n",
    "            'ncols': SQUARE_SHAPE,\n",
    "            'pos_bull': POS_BULL,\n",
    "            'pos_fire': POS_FIRE,\n",
    "            't_move': T_MOVE,\n",
    "            't_shoot': T_SHOOT,\n",
    "            't_any': T_ANY,\n",
    "            #'model': MODEL,\n",
    "            'name_model': NAME_MODEL,\n",
    "            'total_proces': TOTAL_PROCS,\n",
    "            'steps_threshold': STEPS_TRESH,\n",
    "            'env_seed': ENV_SEED,\n",
    "            'name_reward': NAME_REWARD,\n",
    "            'obs_wrapper': OBS_WRAP,\n",
    "            'policy_type': POLICY_TYPE#\"MlpPolicy\"\n",
    "        }\n",
    "\n",
    "        run_name = f\"avatar-fire-master-{instance_value}-{'a' if POS_FIRE == (5, 0) else 'b'}\"\n",
    "        print(run_name)\n",
    "        env_fn = make_env(ProtoEnv, 0, parameters)  # Get the environment creation function\n",
    "        env = env_fn()  # Create the environment instance\n",
    "        loaded_model = PPO.load(os.path.join(save_dir, run_name + \".zip\"), env=env)  # Load the trained model\n",
    "\n",
    "        obs = env.reset()\n",
    "        #print(obs)\n",
    "\n",
    "\n",
    "        for essay in range(ESSAYS):\n",
    "            total_reward = 0.0\n",
    "            done = False\n",
    "            step = 0\n",
    "            threshold = 15\n",
    "            env.reset()\n",
    "            #env.render()\n",
    "\n",
    "            images = []\n",
    "            obs = env.reset()\n",
    "            img = env.render()\n",
    "\n",
    "            while not done: # and step < threshold:\n",
    "                #print(step)\n",
    "                images.append(img)\n",
    "                obs_reshaped = np.expand_dims(np.expand_dims(obs, axis=0), axis=0)  # Reshape the observation\n",
    "                action = loaded_model.predict(obs, deterministic=True)[0]\n",
    "                obs, reward, done, info = env.step(action)\n",
    "                total_reward += reward\n",
    "                step += 1\n",
    "                env.render()\n",
    "                img = env.render()\n",
    "\n",
    "            print('Done', done, step)\n",
    "            print('Total_reward', total_reward)\n",
    "\n",
    "            burt_nodes = np.sum(np.where(env.grid == 25, 1, 0))\n",
    "\n",
    "            RL_objective[run_name] = {\n",
    "                'total_reward': total_reward,\n",
    "                'burt_nodes': burt_nodes,\n",
    "                'step': step\n",
    "            }\n",
    "\n",
    "            save_dir_gif = f\"gifs\"\n",
    "            os.makedirs(save_dir_gif, exist_ok=True)\n",
    "\n",
    "            gif_name = save_dir_gif + f\"/{run_name}\" + f\"-{str(essay)}\"\n",
    "            imageio.mimsave(f\"{gif_name}.gif\", images, fps=3)\n",
    "            env.close()\n",
    "\n",
    "# save the RL_objective\n",
    "import pickle\n",
    "with open('RL_objective.pkl', 'wb') as f:\n",
    "    pickle.dump(RL_objective, f, pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T21:09:43.300811048Z",
     "start_time": "2023-06-13T21:09:43.268907901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "17.0"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T16:59:48.085953650Z",
     "start_time": "2023-06-13T16:59:48.075513691Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "loaded_model = PPO.load(os.path.join(save_dir, run_name + \".zip\"))  # Include the file extension when loading\n",
    "\n",
    "# Check that the prediction is the same after loading (for the same observation)\n",
    "#print(\"loaded\", loaded_model.predict(obs, deterministic=True))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T00:24:29.726473665Z",
     "start_time": "2023-06-12T00:24:28.360411739Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#loaded_model = PPO.load(save_dir + run_name)\n",
    "# Check that the prediction is the same after loading (for the same observation)\n",
    "#print(\"loaded\", loaded_model.predict(obs, deterministic=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T21:54:03.163526603Z",
     "start_time": "2023-06-09T21:54:03.152508488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T21:54:03.652180189Z",
     "start_time": "2023-06-09T21:54:03.647829397Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T21:54:04.067351825Z",
     "start_time": "2023-06-09T21:54:04.059050559Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T21:54:04.932703105Z",
     "start_time": "2023-06-09T21:54:04.931203147Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import imageio\n",
    "from wrappers import ObservationOneHotWrapper\n",
    "from reward_wrappers import NumTreesReward, NumTreesRewardStepOne\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stock_envs import make_env\n",
    "\n",
    "INSTANCE_VALUE = 2\n",
    "\n",
    "MODEL = PPO\n",
    "NAME_MODEL = 'PPO'\n",
    "TOTAL_PROCS = 8\n",
    "TRAIN_STEPS = 1000#6e6\n",
    "STEPS_TRESH = int(1000)\n",
    "ENV_SEED = 100\n",
    "NAME_REWARD = 'NumTreesRewardStepOne'\n",
    "OBS_WRAP = 'ObservationOneHotWrapper_dict_box'\n",
    "POLICY_TYPE = 'MultiInputPolicy'\n",
    "\n",
    "move_values = {\n",
    "    0: {\"T_MOVE\": 0.025, \"T_SHOOT\": 0.1, \"T_ANY\": 0.025},\n",
    "    1: {\"T_MOVE\": 0.05, \"T_SHOOT\": 0.3, \"T_ANY\": 0.05},\n",
    "    2: {\"T_MOVE\": 0.1, \"T_SHOOT\": 0.5, \"T_ANY\": 0.05},\n",
    "    3: {\"T_MOVE\": 0.5, \"T_SHOOT\": 0.5, \"T_ANY\": 0.05},\n",
    "}\n",
    "\n",
    "T_MOVE = move_values[INSTANCE_VALUE][\"T_MOVE\"]\n",
    "T_SHOOT = move_values[INSTANCE_VALUE][\"T_SHOOT\"]\n",
    "T_ANY = move_values[INSTANCE_VALUE][\"T_ANY\"]\n",
    "\n",
    "parameters = {\n",
    "    'nrows': SQUARE_SHAPE,\n",
    "    'ncols': SQUARE_SHAPE,\n",
    "    'pos_bull': POS_BULL,\n",
    "    'pos_fire': POS_FIRE,\n",
    "    't_move': T_MOVE,\n",
    "    't_shoot': T_SHOOT,\n",
    "    't_any': T_ANY,\n",
    "    #'model': MODEL,\n",
    "    'name_model': NAME_MODEL,\n",
    "    'total_proces': TOTAL_PROCS,\n",
    "    'steps_threshold': STEPS_TRESH,\n",
    "    'env_seed': ENV_SEED,\n",
    "    'name_reward': NAME_REWARD,\n",
    "    'obs_wrapper': OBS_WRAP,\n",
    "    'policy_type': POLICY_TYPE#\"MlpPolicy\"\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T00:25:48.390814571Z",
     "start_time": "2023-06-12T00:25:48.349255078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "{'grid': array([[[0., 0., 0., 1., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 1., 1., 0., 0., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]]), 'time': array([0.], dtype=float32)}\n",
      "Total Reward: 0.07894736842105263\n"
     ]
    }
   ],
   "source": [
    "env_fn = make_env(ProtoEnv, 0, parameters)  # Get the environment creation function\n",
    "env = env_fn()  # Create the environment instance\n",
    "loaded_model = PPO.load(os.path.join(save_dir, run_name + \".zip\"), env=env)  # Load the trained model\n",
    "\n",
    "obs = env.reset()\n",
    "print(obs)\n",
    "#obs = np.expand_dims(obs, axis=0)  # Expand the observation shape to (1, 1)\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action, _ = loaded_model.predict(obs, deterministic=True)  # Get the action from the model\n",
    "    obs, reward, done, _ = env.step(action)  # Take the action in the environment\n",
    "    total_reward += reward\n",
    "    env.render()\n",
    "\n",
    "print('Total Reward:', total_reward)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-10T00:14:16.259309292Z",
     "start_time": "2023-06-10T00:13:31.806834695Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "{'grid': array([[[0., 0., 0., 1., 0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 1., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1., 1., 1., 0., 1.],\n",
      "        [0., 1., 1., 1., 1., 1., 0., 0., 0., 1.],\n",
      "        [0., 1., 1., 0., 0., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]]), 'time': array([0.], dtype=float32)}\n",
      "Done True 11\n",
      "Total_reward 0.7894736842105263\n",
      "Done True 11\n",
      "Total_reward 0.7894736842105263\n",
      "Done True 11\n",
      "Total_reward 0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "from wrappers import ObservationOneHotWrapper\n",
    "from reward_wrappers import NumTreesReward, NumTreesRewardStepOne\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stock_envs import make_env\n",
    "\n",
    "\n",
    "\n",
    "# Play\n",
    "ESSAYS = 3\n",
    "train_steps = 'k'\n",
    "\n",
    "\n",
    "env_fn = make_env(ProtoEnv, 0, parameters)  # Get the environment creation function\n",
    "env = env_fn()  # Create the environment instance\n",
    "loaded_model = PPO.load(os.path.join(save_dir, run_name + \".zip\"), env=env)  # Load the trained model\n",
    "\n",
    "obs = env.reset()\n",
    "print(obs)\n",
    "#obs = np.expand_dims(obs, axis=0)  # Expand the observation shape to (1, 1)\n",
    "\n",
    "# while not done:\n",
    "#     action, _ = loaded_model.predict(obs, deterministic=True)  # Get the action from the model\n",
    "#     obs, reward, done, _ = env.step(action)  # Take the action in the environment\n",
    "#     total_reward += reward\n",
    "#     env.render()\n",
    "#\n",
    "# print('Total Reward:', total_reward)\n",
    "\n",
    "\n",
    "\n",
    "for essay in range(ESSAYS):\n",
    "    total_reward = 0.0\n",
    "    done = False\n",
    "    step = 0\n",
    "    threshold = 15\n",
    "    env.reset()\n",
    "    #env.render()\n",
    "\n",
    "    images = []\n",
    "    obs = env.reset()\n",
    "    img = env.render()\n",
    "\n",
    "    while not done: # and step < threshold:\n",
    "        #print(step)\n",
    "        images.append(img)\n",
    "        obs_reshaped = np.expand_dims(np.expand_dims(obs, axis=0), axis=0)  # Reshape the observation\n",
    "        action = loaded_model.predict(obs, deterministic=True)[0]\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        step += 1\n",
    "        env.render()\n",
    "        img = env.render()\n",
    "\n",
    "    print('Done', done, step)\n",
    "    print('Total_reward', total_reward)\n",
    "\n",
    "    save_dir_gif = f\"gifs\"\n",
    "    os.makedirs(save_dir_gif, exist_ok=True)\n",
    "\n",
    "    gif_name = save_dir_gif + f\"/{run_name}\" + f\"-{str(essay)}\"\n",
    "    imageio.mimsave(f\"{gif_name}.gif\", images, fps=3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T00:27:34.635466077Z",
     "start_time": "2023-06-12T00:27:19.057283748Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(i)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T03:58:04.612854004Z",
     "start_time": "2023-06-12T03:58:04.587786598Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
