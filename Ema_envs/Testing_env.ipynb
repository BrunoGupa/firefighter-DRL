{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-09T05:29:14.994446606Z",
     "start_time": "2023-06-09T05:29:14.151135990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x432 with 4 Axes>",
      "image/png": "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\n"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x432 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import gym_cellular_automata as gymca\n",
    "\n",
    "# benchmark mode\n",
    "#env_id = gymca.envs[1]\n",
    "#env = gym.make(env_id)\n",
    "#env.reset()\n",
    "#env.render()\n",
    "\n",
    "# prototype mode\n",
    "#ProtoEnv = gymca.prototypes[1]\n",
    "#env = ProtoEnv(nrows=10, ncols=10)\n",
    "#env.reset()\n",
    "#env.render()\n",
    "\n",
    "\n",
    "SQUARE_SHAPE = 10\n",
    "T_MOVE = 0.025\n",
    "T_SHOOT = 0.1\n",
    "T_ANY = 0.025\n",
    "POS_BULL = [SQUARE_SHAPE-1, SQUARE_SHAPE-1]\n",
    "BULL_POS = f'{SQUARE_SHAPE-1}.{SQUARE_SHAPE-1}'\n",
    "POS_FIRE = (5,0)\n",
    "\n",
    "\n",
    "ProtoEnv = gymca.prototypes[1]\n",
    "env = ProtoEnv(nrows=SQUARE_SHAPE,\n",
    "               ncols=SQUARE_SHAPE,\n",
    "               pos_bull=POS_BULL,\n",
    "               pos_fire=POS_FIRE,\n",
    "               t_move=T_MOVE,\n",
    "               t_shoot=T_SHOOT,\n",
    "               t_any=T_ANY)\n",
    "\n",
    "env.reset()\n",
    "env.render()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0,  0,  0,  3,  0,  0,  3,  3,  3,  3],\n       [ 0,  0,  0,  0,  3,  0,  3,  3,  3,  3],\n       [ 0,  0,  0,  0,  3,  0,  0,  3,  0,  3],\n       [ 0,  0,  0,  0,  0,  3,  0,  0,  3,  3],\n       [ 0,  0,  0,  0,  3,  3,  3,  3,  0,  3],\n       [25,  3,  3,  3,  3,  3,  0,  0,  0,  3],\n       [ 0,  3,  3,  0,  0,  3,  3,  0,  0,  0],\n       [ 0,  0,  3,  3,  3,  0,  0,  0,  0,  0],\n       [ 0,  0,  0,  0,  0,  3,  3,  0,  0,  0],\n       [ 0,  0,  0,  0,  0,  0,  0,  3,  3,  0]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.grid"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T05:29:16.087575599Z",
     "start_time": "2023-06-09T05:29:16.069906593Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Solver_Firefighter.reward_wrappers import NumTreesRewardStepOne\n",
    "import numpy as np\n",
    "\n",
    "SQUARE_SHAPE = 10\n",
    "T_MOVE = 0.025\n",
    "T_SHOOT = 0.1\n",
    "T_ANY = 0.025\n",
    "POS_BULL = [SQUARE_SHAPE-1, SQUARE_SHAPE-1]\n",
    "BULL_POS = f'{SQUARE_SHAPE-1}.{SQUARE_SHAPE-1}'\n",
    "POS_FIRE = (5,0)\n",
    "\n",
    "\n",
    "ProtoEnv = gymca.prototypes[1]\n",
    "env = ProtoEnv(nrows=SQUARE_SHAPE,\n",
    "               ncols=SQUARE_SHAPE,\n",
    "               pos_bull=POS_BULL,\n",
    "               pos_fire=POS_FIRE,\n",
    "               t_move=T_MOVE,\n",
    "               t_shoot=T_SHOOT,\n",
    "               t_any=T_ANY)\n",
    "\n",
    "env.reset()\n",
    "env.render()\n",
    "obs = env.reset()\n",
    "env = NumTreesRewardStepOne(env)\n",
    "#env.render()\n",
    "total_reward = 0.0\n",
    "done = False\n",
    "step = 0\n",
    "threshold = 30\n",
    "\n",
    "env.render()\n",
    "print(\"Total trees: \", np.sum(np.where(env.grid == 3, 1, 0)))\n",
    "total_loss = 0\n",
    "#env.observation_space.sample()\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()  # Your agent goes here!\n",
    "    obs, reward, done, info = env.step([4,1])\n",
    "\n",
    "    env.render()\n",
    "    if reward != 0:\n",
    "        total_loss += reward\n",
    "        print(\"reward\", reward, \"total loss\", total_loss)\n",
    "\n",
    "\n",
    "env.render()\n",
    "print(\"Total trees: \", np.sum(np.where(env.grid == 3, 1, 0)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space.sample())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T05:32:07.423543480Z",
     "start_time": "2023-06-09T05:32:07.402563370Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "40.0"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 0.025"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class ObservationOneHotWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(shape=(256,256), low=0, high=25)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        grid = obs[0]\n",
    "        #print('obs inside')\n",
    "        #print(obs)\n",
    "        #print(obs[1][1])\n",
    "        return grid\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'gym_cellular_automata:ForestFireBulldozer256x256-v3'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gymca.envs[1]\n",
    "#gym.make(env_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C, SAC, PPO, TD3, DQN\n",
    "\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 17       |\n",
      "|    ep_rew_mean      | 17       |\n",
      "|    exploration_rate | 0.871    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 6226     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 68       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | 23.9     |\n",
      "|    exploration_rate | 0.637    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 6532     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 191      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.8     |\n",
      "|    ep_rew_mean      | 22.8     |\n",
      "|    exploration_rate | 0.479    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 6008     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 274      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.335    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 6003     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 350      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.132    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 5954     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 457      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25       |\n",
      "|    ep_rew_mean      | 25       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 5741     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 601      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.9     |\n",
      "|    ep_rew_mean      | 25.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 5844     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 726      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.3     |\n",
      "|    ep_rew_mean      | 25.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 5506     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 811      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.6     |\n",
      "|    ep_rew_mean      | 25.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 5560     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 922      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.9     |\n",
      "|    ep_rew_mean      | 26.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 5642     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1076     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.8     |\n",
      "|    ep_rew_mean      | 26.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 5713     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1178     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 25.5     |\n",
      "|    ep_rew_mean      | 25.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 5694     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1225     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.9     |\n",
      "|    ep_rew_mean      | 24.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 5719     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1293     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.5     |\n",
      "|    ep_rew_mean      | 24.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 5760     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1370     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 24.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 5808     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1454     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.9     |\n",
      "|    ep_rew_mean      | 23.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 5782     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1529     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 23.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 5752     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1584     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 23.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 5796     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1676     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 5920     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1786     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 5827     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1872     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 5944     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1981     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 6068     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2074     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.3     |\n",
      "|    ep_rew_mean      | 23.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 6150     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2140     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 6223     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2200     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 6284     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2259     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 23       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 6390     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2365     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.3     |\n",
      "|    ep_rew_mean      | 22.3     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 6431     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2420     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 6506     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2492     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 6560     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2550     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 6683     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2659     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 6801     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2797     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 6870     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2902     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 6947     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3007     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 7004     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3085     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 7064     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3184     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 7090     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3248     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 7152     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3338     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 7227     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3462     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.8     |\n",
      "|    ep_rew_mean      | 21.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 7289     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3550     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 7311     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3612     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.9     |\n",
      "|    ep_rew_mean      | 21.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 7370     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3714     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.7     |\n",
      "|    ep_rew_mean      | 22.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 7461     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3852     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 7523     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3941     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 7591     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4038     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 7628     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4120     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 7650     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4184     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 7704     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4292     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.9     |\n",
      "|    ep_rew_mean      | 22.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 7782     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4427     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 23       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 7807     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4496     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 23.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 7825     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4582     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 23.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 7846     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4685     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.2     |\n",
      "|    ep_rew_mean      | 23.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 7862     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4745     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 7920     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4868     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 24.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 7965     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4972     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_76950/2481967413.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0maction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdeterministic\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m     \u001B[0mobs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m     \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrender\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m       \u001B[0mobs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/gym/gym/core.py\u001B[0m in \u001B[0;36mrender\u001B[0;34m(self, mode, **kwargs)\u001B[0m\n\u001B[1;32m    293\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mrender\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"human\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 295\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrender\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    296\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    297\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/gym/gym/envs/classic_control/cartpole.py\u001B[0m in \u001B[0;36mrender\u001B[0;34m(self, mode)\u001B[0m\n\u001B[1;32m    227\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpoletrans\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mset_rotation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 229\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mviewer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrender\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreturn_rgb_array\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"rgb_array\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    230\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    231\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/gym/gym/envs/classic_control/rendering.py\u001B[0m in \u001B[0;36mrender\u001B[0;34m(self, return_rgb_array)\u001B[0m\n\u001B[1;32m    143\u001B[0m             \u001B[0marr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbuffer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mheight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwidth\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m             \u001B[0marr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0marr\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 145\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwindow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    146\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0monetime_geoms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    147\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0marr\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mreturn_rgb_array\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misopen\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/pyglet/window/xlib/__init__.py\u001B[0m in \u001B[0;36mflip\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    534\u001B[0m         \u001B[0;31m# TODO canvas.flip?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    535\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 536\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    537\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    538\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sync_resize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/pyglet/gl/xlib.py\u001B[0m in \u001B[0;36mflip\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    374\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_vsync\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    375\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_wait_vsync\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 376\u001B[0;31m         \u001B[0mglx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglXSwapBuffers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mx_display\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mglx_window\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    377\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    378\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=5000, log_interval=4)\n",
    "model.save(\"dqn_cartpole\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DQN.load(\"dqn_cartpole\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "      obs = env.reset()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "env = Monitor(gym.make('Pendulum-v1'))\n",
    "env = DummyVecEnv([lambda: env])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.17e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 235       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.42     |\n",
      "|    explained_variance | 0.0127    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -16.4     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 348       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.04e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 335       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.43     |\n",
      "|    explained_variance | -0.193    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -0.977    |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.42      |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = A2C(\"MlpPolicy\", env, verbose=1).learn(int(1000))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subespaces\n",
      "(GridSpace(values=[ 0  3 25], shape=(256, 256)), Tuple(Box([[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], [[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]], (3, 3), float32), MultiDiscrete([256 256]), Box(0.0, inf, (), float32)))\n",
      "sub_space\n",
      "Tuple(Box([[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]], [[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]], (3, 3), float32), MultiDiscrete([256 256]), Box(0.0, inf, (), float32))\n",
      "s-dict\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tuple' object has no attribute 'Dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_81363/3788470973.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrender\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0menv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMonitor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgym\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmake\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menv_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0menv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDummyVecEnv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;32mlambda\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mA2C\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"MlpPolicy\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlearn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, env_fns)\u001B[0m\n\u001B[1;32m     38\u001B[0m         \u001B[0mVecEnv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menv_fns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobservation_space\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maction_space\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m         \u001B[0mobs_space\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobservation_space\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshapes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtypes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mobs_space_info\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs_space\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuf_obs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOrderedDict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_envs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshapes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/vec_env/util.py\u001B[0m in \u001B[0;36mobs_space_info\u001B[0;34m(obs_space)\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0mdtypes\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0ma\u001B[0m \u001B[0mdict\u001B[0m \u001B[0mmapping\u001B[0m \u001B[0mkeys\u001B[0m \u001B[0mto\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     \"\"\"\n\u001B[0;32m---> 60\u001B[0;31m     \u001B[0mcheck_for_nested_spaces\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs_space\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs_space\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mspaces\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs_space\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspaces\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mOrderedDict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Dict space must have ordered subspaces\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/preprocessing.py\u001B[0m in \u001B[0;36mcheck_for_nested_spaces\u001B[0;34m(obs_space)\u001B[0m\n\u001B[1;32m    228\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msub_space\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m's-dict'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msub_space\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m's-Tuple'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msub_space\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'Tuple' object has no attribute 'Dict'"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x432 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# benchmark mode\n",
    "env_id = gymca.envs[1]\n",
    "env = gym.make(env_id)\n",
    "env = ObservationOneHotWrapper(env)\n",
    "\n",
    "env.reset()\n",
    "env.render()\n",
    "env = Monitor(gym.make(env_id))\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1).learn(int(1000))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 26.8     |\n",
      "|    ep_rew_mean      | 26.8     |\n",
      "|    exploration_rate | 0.797    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 8206     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 107      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 24.2     |\n",
      "|    exploration_rate | 0.631    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 8249     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 194      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 24.2     |\n",
      "|    exploration_rate | 0.447    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 8214     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 291      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 24.2     |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 8107     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 388      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.4     |\n",
      "|    ep_rew_mean      | 22.4     |\n",
      "|    exploration_rate | 0.147    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 8378     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 449      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.6     |\n",
      "|    ep_rew_mean      | 21.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 8704     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 519      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.4     |\n",
      "|    ep_rew_mean      | 21.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 9017     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 599      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 9393     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 705      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 9857     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 848      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 9672     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 953      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.6     |\n",
      "|    ep_rew_mean      | 23.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 9500     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1038     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 24.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 9511     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1159     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 9548     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1240     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.2     |\n",
      "|    ep_rew_mean      | 24.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 9661     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1355     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 9684     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1428     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 23.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 9708     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1518     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24       |\n",
      "|    ep_rew_mean      | 24       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 9469     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1630     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 24.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 9307     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1734     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 9149     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1810     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 9125     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1905     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 9143     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1968     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 9114     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2096     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 9130     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2190     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 9173     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2255     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 9231     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2344     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23       |\n",
      "|    ep_rew_mean      | 23       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 9224     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2405     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.4     |\n",
      "|    ep_rew_mean      | 23.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 9352     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2536     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 9398     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2671     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.5     |\n",
      "|    ep_rew_mean      | 23.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 9384     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2740     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.8     |\n",
      "|    ep_rew_mean      | 23.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 9381     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2825     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 24.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 9364     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2925     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 24.1     |\n",
      "|    ep_rew_mean      | 24.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 9401     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3004     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.7     |\n",
      "|    ep_rew_mean      | 23.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 9435     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3075     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 23.1     |\n",
      "|    ep_rew_mean      | 23.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 9482     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3154     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.6     |\n",
      "|    ep_rew_mean      | 22.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 9518     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3214     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.5     |\n",
      "|    ep_rew_mean      | 22.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 9558     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3287     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 9609     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3377     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22.2     |\n",
      "|    ep_rew_mean      | 22.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 9650     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3464     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 9679     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3528     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 22       |\n",
      "|    ep_rew_mean      | 22       |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 9740     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3631     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.7     |\n",
      "|    ep_rew_mean      | 21.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 9762     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3686     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.1     |\n",
      "|    ep_rew_mean      | 21.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 9785     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3745     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 9813     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3809     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 21.2     |\n",
      "|    ep_rew_mean      | 21.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 9884     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3930     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 9895     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3986     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 9924     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4060     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.9     |\n",
      "|    ep_rew_mean      | 20.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 9978     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4187     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 9997     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4253     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.8     |\n",
      "|    ep_rew_mean      | 20.8     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 10020    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4333     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.6     |\n",
      "|    ep_rew_mean      | 20.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 10042    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4406     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.7     |\n",
      "|    ep_rew_mean      | 20.7     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 10063    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4477     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.2     |\n",
      "|    ep_rew_mean      | 20.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 10084    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4556     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.1     |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 10123    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4683     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.5     |\n",
      "|    ep_rew_mean      | 20.5     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 10164    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4794     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 20.4     |\n",
      "|    ep_rew_mean      | 20.4     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 10177    |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4866     |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_76950/1768038803.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0maction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_states\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdeterministic\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m     \u001B[0mobs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m     \u001B[0;31m#env.render()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/gym/gym/wrappers/time_limit.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m     16\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_elapsed_steps\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m         ), \"Cannot call env.step() before calling reset()\"\n\u001B[0;32m---> 18\u001B[0;31m         \u001B[0mobservation\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minfo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_elapsed_steps\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_elapsed_steps\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_max_episode_steps\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/gym/gym/envs/classic_control/cartpole.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m         \u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_dot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtheta\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtheta_dot\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 108\u001B[0;31m         \u001B[0mforce\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforce_mag\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0maction\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforce_mag\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    109\u001B[0m         \u001B[0mcostheta\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcos\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtheta\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    110\u001B[0m         \u001B[0msintheta\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtheta\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "#env_id = gymca.envs[1]\n",
    "#env = gym.make(env_id)\n",
    "#env.reset()\n",
    "#env.render()\n",
    "\n",
    "\n",
    "model = DQN(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=5000, log_interval=4)\n",
    "model.save(\"dqn_b\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = DQN.load(\"dqn_b\")\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #env.render()\n",
    "    if done:\n",
    "      obs = env.reset()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Nested observation spaces are not supported (Tuple/Dict space inside Tuple/Dict space).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_76950/609363696.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;31m#SAC, PPO, TD3\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTD3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'MlpPolicy'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlearn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m8000\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;31m# The model will be saved under PPO_tutorial.zip\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msave_dir\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"/PPO_tutorial\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/td3/td3.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_delay, target_policy_noise, target_noise_clip, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001B[0m\n\u001B[1;32m     96\u001B[0m     ):\n\u001B[1;32m     97\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 98\u001B[0;31m         super().__init__(\n\u001B[0m\u001B[1;32m     99\u001B[0m             \u001B[0mpolicy\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m             \u001B[0menv\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_kwargs, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, use_sde_at_warmup, sde_support, supported_action_spaces)\u001B[0m\n\u001B[1;32m    104\u001B[0m     ):\n\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 106\u001B[0;31m         super().__init__(\n\u001B[0m\u001B[1;32m    107\u001B[0m             \u001B[0mpolicy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpolicy\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    108\u001B[0m             \u001B[0menv\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/base_class.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, policy, env, learning_rate, policy_kwargs, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001B[0m\n\u001B[1;32m    158\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0menv\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m             \u001B[0menv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmaybe_make_env\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 160\u001B[0;31m             \u001B[0menv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_wrap_env\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmonitor_wrapper\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    161\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobservation_space\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobservation_space\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/base_class.py\u001B[0m in \u001B[0;36m_wrap_env\u001B[0;34m(env, verbose, monitor_wrapper)\u001B[0m\n\u001B[1;32m    207\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mverbose\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    208\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Wrapping the env in a DummyVecEnv.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 209\u001B[0;31m             \u001B[0menv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDummyVecEnv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;32mlambda\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    210\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    211\u001B[0m         \u001B[0;31m# Make sure that dict-spaces are not nested (not supported)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, env_fns)\u001B[0m\n\u001B[1;32m     38\u001B[0m         \u001B[0mVecEnv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menv_fns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobservation_space\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maction_space\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m         \u001B[0mobs_space\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobservation_space\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshapes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtypes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mobs_space_info\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs_space\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuf_obs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOrderedDict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_envs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshapes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mk\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeys\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/vec_env/util.py\u001B[0m in \u001B[0;36mobs_space_info\u001B[0;34m(obs_space)\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0mdtypes\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0ma\u001B[0m \u001B[0mdict\u001B[0m \u001B[0mmapping\u001B[0m \u001B[0mkeys\u001B[0m \u001B[0mto\u001B[0m \u001B[0mdtypes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     \"\"\"\n\u001B[0;32m---> 60\u001B[0;31m     \u001B[0mcheck_for_nested_spaces\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs_space\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs_space\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mspaces\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobs_space\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mspaces\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mOrderedDict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Dict space must have ordered subspaces\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/preprocessing.py\u001B[0m in \u001B[0;36mcheck_for_nested_spaces\u001B[0;34m(obs_space)\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0msub_space\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msub_spaces\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msub_space\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mspaces\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDict\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mspaces\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 225\u001B[0;31m                 raise NotImplementedError(\n\u001B[0m\u001B[1;32m    226\u001B[0m                     \u001B[0;34m\"Nested observation spaces are not supported (Tuple/Dict space inside Tuple/Dict space).\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    227\u001B[0m                 )\n",
      "\u001B[0;31mNotImplementedError\u001B[0m: Nested observation spaces are not supported (Tuple/Dict space inside Tuple/Dict space)."
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x432 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "save_dir = \"test_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "env_id = gymca.envs[1]\n",
    "env = gym.make(env_id)\n",
    "env.reset()\n",
    "env.render()\n",
    "\n",
    "#SAC, PPO, TD3\n",
    "model = TD3('MlpPolicy', env, verbose=0).learn(8000)\n",
    "# The model will be saved under PPO_tutorial.zip\n",
    "model.save(save_dir + \"/PPO_tutorial\")\n",
    "\n",
    "# sample an observation from the environment\n",
    "obs = model.env.observation_space.sample()\n",
    "\n",
    "# Check prediction before saving\n",
    "print(\"pre saved\", model.predict(obs, deterministic=True))\n",
    "\n",
    "del model # delete trained model to demonstrate loading\n",
    "\n",
    "loaded_model = PPO.load(save_dir + \"/PPO_tutorial\")\n",
    "# Check that the prediction is the same after loading (for the same observation)\n",
    "print(\"loaded\", loaded_model.predict(obs, deterministic=True))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_cellular_automata as gymca\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import A2C, SAC, PPO, TD3, DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "SQUARE_SHAPE = 10\n",
    "T_MOVE = 0.05\n",
    "T_SHOOT = 0.05\n",
    "POS_BULL = None#[SQUARE_SHAPE-1, SQUARE_SHAPE-1]\n",
    "BULL_POS = None#f'{SQUARE_SHAPE-1}.{SQUARE_SHAPE-1}'\n",
    "\n",
    "# we stablish t_any = T_move\n",
    "\n",
    "MODEL = PPO\n",
    "NAME_MODEL = 'PPO'\n",
    "\n",
    "\n",
    "dir_name = f\"{NAME_MODEL}_{SQUARE_SHAPE}-{T_MOVE}-{T_SHOOT}-{BULL_POS}\"\n",
    "#mcm_time_actions =\n",
    "\n",
    "class ObservationOneHotWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        self.shape = shape\n",
    "        #self.observation_space = gym.spaces.MultiBinary([3, shape, shape])\n",
    "\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            {\"grid\": gym.spaces.MultiBinary([3, shape, shape]),\n",
    "             \"time\": gym.spaces.Discrete(40)\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def observation(self, obs):\n",
    "        #print('obs inside')\n",
    "        #print(obs)\n",
    "        grid = obs[0]\n",
    "        row, col = obs[1][1]\n",
    "        #print('pos:', row, col)\n",
    "        grid_pos = np.zeros((self.shape, self.shape))\n",
    "        grid_pos[row, col] = 1\n",
    "        grid_tree = np.where(grid == 3, 1, 0)\n",
    "        grid_fire = np.where(grid == 25, 1, 0)\n",
    "\n",
    "        #Time_Space\n",
    "        time = obs[1][-1]\n",
    "        module = int(time // 0.025)\n",
    "        if module >= 40:\n",
    "            module = 39\n",
    "        return {\"grid\": [grid_tree, grid_fire, grid_pos],\n",
    "                \"time\": int(module)}\n",
    "\n",
    "\n",
    "class NumTreesReward(gym.RewardWrapper):\n",
    "    #Returns the number of trees at the end of the episode\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "\n",
    "    def reward(self, rew):\n",
    "        if self.done:\n",
    "            #print(self.grid)\n",
    "            grid_tree = np.where(self.grid == 3, 1, 0)\n",
    "            unique, counts = np.unique(grid_tree, return_counts=True)\n",
    "            try:\n",
    "                return counts[1]\n",
    "            except IndexError:\n",
    "                # There are not any tree\n",
    "                return 0\n",
    "        return 0\n",
    "\n",
    "\n",
    "def make_env(env_id, rank, seed=0):\n",
    "    \"\"\"\n",
    "    Utility function for multiprocessed env.\n",
    "\n",
    "    :param env_id: (str) the environment ID\n",
    "    :param seed: (int) the inital seed for RNG\n",
    "    :param rank: (int) index of the subprocess\n",
    "    \"\"\"\n",
    "    def _init():\n",
    "        #env = gym.make(env_id)\n",
    "        # Important: use a different seed for each environment\n",
    "\n",
    "        env = env_id(nrows=SQUARE_SHAPE,\n",
    "               ncols=SQUARE_SHAPE,\n",
    "               pos_bull=POS_BULL,\n",
    "               t_move=T_MOVE,\n",
    "               t_shoot=T_SHOOT,\n",
    "               t_any=T_MOVE)\n",
    "        env = ObservationOneHotWrapper(env, shape=SQUARE_SHAPE)\n",
    "        env = NumTreesReward(env)\n",
    "\n",
    "        env.seed(seed + rank)\n",
    "\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 432  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 4    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "ProtoEnv = gymca.prototypes[1]\n",
    "total_procs = 1\n",
    "\n",
    "env = DummyVecEnv([make_env(ProtoEnv, i+total_procs) for i in range(total_procs)])\n",
    "\n",
    "#env = make_vec_env(env, n_envs=4)\n",
    "\n",
    "model = MODEL(\"MultiInputPolicy\", env, verbose=1).learn(int(1000))\n",
    "#model = PPO('MlpPolicy', 'Pendulum-v1', verbose=0).learn(8000)\n",
    "\n",
    "# Create save dir\n",
    "save_dir = \"test_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "model.save(save_dir + f\"/{dir_name}\")\n",
    "env.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('img',\n              array([[[186],\n                      [245],\n                      [ 25],\n                      ...,\n                      [ 50],\n                      [ 98],\n                      [173]],\n              \n                     [[ 77],\n                      [ 90],\n                      [100],\n                      ...,\n                      [171],\n                      [139],\n                      [197]],\n              \n                     [[119],\n                      [164],\n                      [179],\n                      ...,\n                      [194],\n                      [ 21],\n                      [254]],\n              \n                     ...,\n              \n                     [[218],\n                      [244],\n                      [148],\n                      ...,\n                      [247],\n                      [123],\n                      [244]],\n              \n                     [[203],\n                      [ 58],\n                      [167],\n                      ...,\n                      [118],\n                      [153],\n                      [212]],\n              \n                     [[145],\n                      [211],\n                      [118],\n                      ...,\n                      [167],\n                      [ 15],\n                      [ 37]]], dtype=uint8)),\n             ('vec',\n              array([0.72816065, 0.79818771, 0.10875087, 0.42123505, 0.63098582]))])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.envs import SimpleMultiObsEnv\n",
    "\n",
    "\n",
    "# Stable Baselines provides SimpleMultiObsEnv as an example environment with Dict observations\n",
    "env = SimpleMultiObsEnv(random_start=False)\n",
    "env.observation_space.sample()\n",
    "#model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "#model.learn(total_timesteps=10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded: gamma = 0.99 n_steps = 2048\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 5205  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 6     |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1850        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018981984 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.603       |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 4.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1526        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018862724 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.36       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.865       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 6.96        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1404        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020280171 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0258     |\n",
      "|    value_loss           | 5.57        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1337        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020148247 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.819       |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0271     |\n",
      "|    value_loss           | 4.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1294        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019172113 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.3        |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 8.6         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1267        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020524615 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.28       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.759       |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 9.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1245        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021013957 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.26       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.808       |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 6.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1232        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022020232 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.568       |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 3.61        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1223        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022270158 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.748       |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 7.68        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1211        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022111308 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1           |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.0255     |\n",
      "|    value_loss           | 7.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1193        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023226265 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.835       |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0256     |\n",
      "|    value_loss           | 8.93        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1178        |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 361         |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022247624 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.16       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0265     |\n",
      "|    value_loss           | 6.77        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1171        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023484403 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.11       |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.58        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 8.55        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1166        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022866106 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 7.19        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1164       |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 450        |\n",
      "|    total_timesteps      | 524288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02303131 |\n",
      "|    clip_fraction        | 0.234      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.08      |\n",
      "|    explained_variance   | 0.732      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | -0.0256    |\n",
      "|    value_loss           | 8.81       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1157        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023397565 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.85        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 6.57        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1151       |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 512        |\n",
      "|    total_timesteps      | 589824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02348641 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.06      |\n",
      "|    explained_variance   | 0.721      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.54       |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.0258    |\n",
      "|    value_loss           | 9.54       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1149        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 541         |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023320701 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1147        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023192566 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.33        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 12.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1147        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 599         |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023771353 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.72        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 12.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1147        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 628         |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025473483 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0252     |\n",
      "|    value_loss           | 11.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1144        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 658         |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023945497 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.87        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 11.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1142        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 688         |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024765475 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.8         |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 11.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1140        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 718         |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024368485 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    value_loss           | 17.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1138      |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 748       |\n",
      "|    total_timesteps      | 851968    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0246804 |\n",
      "|    clip_fraction        | 0.245     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.88     |\n",
      "|    explained_variance   | 0.634     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.84      |\n",
      "|    n_updates            | 560       |\n",
      "|    policy_gradient_loss | -0.0233   |\n",
      "|    value_loss           | 15.6      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1137        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025794039 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.41        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0249     |\n",
      "|    value_loss           | 15.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1132        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 810         |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026080381 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.7        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 14.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1123        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 846         |\n",
      "|    total_timesteps      | 950272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024535017 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.71        |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 14.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1119        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 878         |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024591027 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 21.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1114        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 911         |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025890544 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.74        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0235     |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1105        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 948         |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024943823 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.28        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1103        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 979         |\n",
      "|    total_timesteps      | 1081344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026055582 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1102        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 1010        |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026658865 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.68        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1099       |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 1043       |\n",
      "|    total_timesteps      | 1146880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02552948 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.66      |\n",
      "|    explained_variance   | 0.623      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.6        |\n",
      "|    n_updates            | 650        |\n",
      "|    policy_gradient_loss | -0.0206    |\n",
      "|    value_loss           | 23.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1096        |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 1075        |\n",
      "|    total_timesteps      | 1179648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028397666 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.85        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1096       |\n",
      "|    iterations           | 37         |\n",
      "|    time_elapsed         | 1105       |\n",
      "|    total_timesteps      | 1212416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02645976 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.65      |\n",
      "|    explained_variance   | 0.663      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.91       |\n",
      "|    n_updates            | 670        |\n",
      "|    policy_gradient_loss | -0.022     |\n",
      "|    value_loss           | 16.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1096        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 1135        |\n",
      "|    total_timesteps      | 1245184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027450893 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.84        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 16.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1096        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 1165        |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027573328 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.24        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    value_loss           | 18.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1094        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 1197        |\n",
      "|    total_timesteps      | 1310720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026696634 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.86        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 19.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1094        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 1227        |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026465721 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.67        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 17.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1092        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 1259        |\n",
      "|    total_timesteps      | 1376256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027907172 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.11        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 16.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1091        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 1290        |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026935508 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.41        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 16.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1091        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 1321        |\n",
      "|    total_timesteps      | 1441792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026797155 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.14        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 1352        |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026370678 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.13        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 16.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 1383        |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026571706 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.88        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 18.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 1413        |\n",
      "|    total_timesteps      | 1540096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027055928 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.4         |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 1443        |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025171757 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.648       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.31        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 1473        |\n",
      "|    total_timesteps      | 1605632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027000282 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.27        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 22.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 1504        |\n",
      "|    total_timesteps      | 1638400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026766341 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.42        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 22.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 1534        |\n",
      "|    total_timesteps      | 1671168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026006632 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.77        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 20.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1088       |\n",
      "|    iterations           | 52         |\n",
      "|    time_elapsed         | 1565       |\n",
      "|    total_timesteps      | 1703936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02597269 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.613      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4          |\n",
      "|    n_updates            | 820        |\n",
      "|    policy_gradient_loss | -0.0193    |\n",
      "|    value_loss           | 22.5       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1088       |\n",
      "|    iterations           | 53         |\n",
      "|    time_elapsed         | 1595       |\n",
      "|    total_timesteps      | 1736704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02687239 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | 0.634      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.09       |\n",
      "|    n_updates            | 830        |\n",
      "|    policy_gradient_loss | -0.0201    |\n",
      "|    value_loss           | 20.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1088        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 1625        |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026419938 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.19        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 21.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1088        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 1655        |\n",
      "|    total_timesteps      | 1802240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026570953 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1089       |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 1684       |\n",
      "|    total_timesteps      | 1835008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02794418 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 0.621      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11         |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.0199    |\n",
      "|    value_loss           | 21         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 1713        |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027049648 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 23.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 1743        |\n",
      "|    total_timesteps      | 1900544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028247137 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.01        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 22.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 1772        |\n",
      "|    total_timesteps      | 1933312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027784478 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.15        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 1802        |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026870936 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.42        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 28.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 1832        |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028727481 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.78        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 25.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 1862        |\n",
      "|    total_timesteps      | 2031616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027344879 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.77        |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 1892        |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026464231 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.57        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.58        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 26.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 1922        |\n",
      "|    total_timesteps      | 2097152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028105225 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.82        |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 1952        |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025953384 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.08        |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 26.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 1982        |\n",
      "|    total_timesteps      | 2162688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025993316 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.31        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 2013        |\n",
      "|    total_timesteps      | 2195456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026704501 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1090       |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 2043       |\n",
      "|    total_timesteps      | 2228224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02733168 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0.625      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.99       |\n",
      "|    n_updates            | 980        |\n",
      "|    policy_gradient_loss | -0.0186    |\n",
      "|    value_loss           | 25.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1090        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 2074        |\n",
      "|    total_timesteps      | 2260992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026051607 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.59        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.49        |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 2104        |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026497878 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.38        |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 2135        |\n",
      "|    total_timesteps      | 2326528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025694432 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1089        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 2166        |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026199996 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.79        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 27.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1088        |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 2197        |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027376302 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 26.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1088        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 2227        |\n",
      "|    total_timesteps      | 2424832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026338203 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.68        |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 27.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1088        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 2258        |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025961371 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 28.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1088        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 2288        |\n",
      "|    total_timesteps      | 2490368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025470596 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.991      |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5           |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 29.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1087       |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 2319       |\n",
      "|    total_timesteps      | 2523136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02735844 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.993     |\n",
      "|    explained_variance   | 0.528      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 17.3       |\n",
      "|    n_updates            | 1070       |\n",
      "|    policy_gradient_loss | -0.0178    |\n",
      "|    value_loss           | 29.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1087        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 2350        |\n",
      "|    total_timesteps      | 2555904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027705953 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.49        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 29.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1087        |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 2380        |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024660856 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.991      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.48        |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1087        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 2411        |\n",
      "|    total_timesteps      | 2621440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026487626 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 31.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1086       |\n",
      "|    iterations           | 81         |\n",
      "|    time_elapsed         | 2442       |\n",
      "|    total_timesteps      | 2654208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02575795 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.965     |\n",
      "|    explained_variance   | 0.503      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.3        |\n",
      "|    n_updates            | 1110       |\n",
      "|    policy_gradient_loss | -0.0171    |\n",
      "|    value_loss           | 33.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1086        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 2473        |\n",
      "|    total_timesteps      | 2686976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025017185 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.955      |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1085        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 2506        |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023527883 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.927      |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1084        |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 2538        |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026611323 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.942      |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1084        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 2568        |\n",
      "|    total_timesteps      | 2785280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025396576 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.937      |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.92        |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1082        |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 2602        |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025991306 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.916      |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 35.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 2635        |\n",
      "|    total_timesteps      | 2850816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025113886 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.909      |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 2666        |\n",
      "|    total_timesteps      | 2883584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026081845 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.915      |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 2697        |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024439793 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.912      |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.1        |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 2732        |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025142062 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.874      |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 36.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 2761        |\n",
      "|    total_timesteps      | 2981888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024927108 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.893      |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.85        |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 38.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 2791        |\n",
      "|    total_timesteps      | 3014656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023780074 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.893      |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1080        |\n",
      "|    iterations           | 93          |\n",
      "|    time_elapsed         | 2821        |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025746781 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.899      |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1079       |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 2852       |\n",
      "|    total_timesteps      | 3080192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02565154 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.906     |\n",
      "|    explained_variance   | 0.533      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.44       |\n",
      "|    n_updates            | 1240       |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    value_loss           | 39.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 2883        |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024943966 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.89       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.18        |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 40.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 2914        |\n",
      "|    total_timesteps      | 3145728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025970835 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 39.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 2944        |\n",
      "|    total_timesteps      | 3178496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023337953 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.865      |\n",
      "|    explained_variance   | 0.562       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 43.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 2974        |\n",
      "|    total_timesteps      | 3211264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024329703 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.866      |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 3005        |\n",
      "|    total_timesteps      | 3244032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024148915 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.834      |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.75        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 44.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 3036        |\n",
      "|    total_timesteps      | 3276800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024359524 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.829      |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 3066        |\n",
      "|    total_timesteps      | 3309568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025060555 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.812      |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 40.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1079       |\n",
      "|    iterations           | 102        |\n",
      "|    time_elapsed         | 3096       |\n",
      "|    total_timesteps      | 3342336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02510636 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.807     |\n",
      "|    explained_variance   | 0.514      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.9       |\n",
      "|    n_updates            | 1320       |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    value_loss           | 42.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 3126        |\n",
      "|    total_timesteps      | 3375104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025938313 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.794      |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 3156        |\n",
      "|    total_timesteps      | 3407872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025100123 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.27        |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 42.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1079       |\n",
      "|    iterations           | 105        |\n",
      "|    time_elapsed         | 3186       |\n",
      "|    total_timesteps      | 3440640    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02475303 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.828     |\n",
      "|    explained_variance   | 0.556      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.4       |\n",
      "|    n_updates            | 1350       |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    value_loss           | 43.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 3217        |\n",
      "|    total_timesteps      | 3473408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025852324 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.823      |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1079       |\n",
      "|    iterations           | 107        |\n",
      "|    time_elapsed         | 3247       |\n",
      "|    total_timesteps      | 3506176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02561095 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.831     |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.55       |\n",
      "|    n_updates            | 1370       |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    value_loss           | 42.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 3276        |\n",
      "|    total_timesteps      | 3538944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024198852 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.826      |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1080        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 3306        |\n",
      "|    total_timesteps      | 3571712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025222208 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.821      |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 48.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1080        |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 3336        |\n",
      "|    total_timesteps      | 3604480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025858827 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.813      |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 45.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1080        |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 3366        |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026300482 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.819      |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1080        |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 3395        |\n",
      "|    total_timesteps      | 3670016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025067799 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.812      |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 3423        |\n",
      "|    total_timesteps      | 3702784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024119623 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 46.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 3452        |\n",
      "|    total_timesteps      | 3735552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026113369 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.777      |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 48          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1082        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 3481        |\n",
      "|    total_timesteps      | 3768320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024387415 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.764      |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1082       |\n",
      "|    iterations           | 116        |\n",
      "|    time_elapsed         | 3510       |\n",
      "|    total_timesteps      | 3801088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02427474 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.763     |\n",
      "|    explained_variance   | 0.597      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19.7       |\n",
      "|    n_updates            | 1460       |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    value_loss           | 50.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1083       |\n",
      "|    iterations           | 117        |\n",
      "|    time_elapsed         | 3539       |\n",
      "|    total_timesteps      | 3833856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02447493 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.743     |\n",
      "|    explained_variance   | 0.591      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.1       |\n",
      "|    n_updates            | 1470       |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    value_loss           | 48.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1083        |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 3567        |\n",
      "|    total_timesteps      | 3866624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025193784 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.733      |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1084        |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 3596        |\n",
      "|    total_timesteps      | 3899392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023451913 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1083        |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 3627        |\n",
      "|    total_timesteps      | 3932160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024548974 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 47.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1083        |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 3658        |\n",
      "|    total_timesteps      | 3964928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024042968 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.681      |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1083        |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 3688        |\n",
      "|    total_timesteps      | 3997696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023045318 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1083        |\n",
      "|    iterations           | 123         |\n",
      "|    time_elapsed         | 3719        |\n",
      "|    total_timesteps      | 4030464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024159651 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.68       |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 45.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1083        |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 3749        |\n",
      "|    total_timesteps      | 4063232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025117433 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1083        |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 3780        |\n",
      "|    total_timesteps      | 4096000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024773855 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.658      |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 47.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1083       |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 3811       |\n",
      "|    total_timesteps      | 4128768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02360022 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.628     |\n",
      "|    explained_variance   | 0.627      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 17.8       |\n",
      "|    n_updates            | 1560       |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    value_loss           | 45.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1082        |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 3842        |\n",
      "|    total_timesteps      | 4161536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023499824 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.62       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1082        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 3873        |\n",
      "|    total_timesteps      | 4194304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022076316 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.593      |\n",
      "|    explained_variance   | 0.619       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 41.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1082        |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 3904        |\n",
      "|    total_timesteps      | 4227072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023141341 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1082        |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 3936        |\n",
      "|    total_timesteps      | 4259840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023753807 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 39.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1082        |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 3966        |\n",
      "|    total_timesteps      | 4292608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022905258 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.539      |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 38.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1082        |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 3997        |\n",
      "|    total_timesteps      | 4325376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021639783 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.517      |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1081       |\n",
      "|    iterations           | 133        |\n",
      "|    time_elapsed         | 4027       |\n",
      "|    total_timesteps      | 4358144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02341852 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.502     |\n",
      "|    explained_variance   | 0.664      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 1630       |\n",
      "|    policy_gradient_loss | -0.0153    |\n",
      "|    value_loss           | 35.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1082        |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 4058        |\n",
      "|    total_timesteps      | 4390912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021128481 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.518      |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 33.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 4088        |\n",
      "|    total_timesteps      | 4423680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023511523 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 4119        |\n",
      "|    total_timesteps      | 4456448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024403661 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.501      |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 33.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 4149        |\n",
      "|    total_timesteps      | 4489216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021469261 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.479      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 32.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 4179        |\n",
      "|    total_timesteps      | 4521984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021673035 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.06        |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 4210        |\n",
      "|    total_timesteps      | 4554752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021655913 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.496      |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12          |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 31.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 4241        |\n",
      "|    total_timesteps      | 4587520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020468663 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.465      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 1700        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 4272        |\n",
      "|    total_timesteps      | 4620288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021921344 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.466      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 28.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1081        |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 4302        |\n",
      "|    total_timesteps      | 4653056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022629332 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 30.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1081       |\n",
      "|    iterations           | 143        |\n",
      "|    time_elapsed         | 4332       |\n",
      "|    total_timesteps      | 4685824    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02164873 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.466     |\n",
      "|    explained_variance   | 0.675      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.5       |\n",
      "|    n_updates            | 1730       |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 30.3       |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1080      |\n",
      "|    iterations           | 144       |\n",
      "|    time_elapsed         | 4367      |\n",
      "|    total_timesteps      | 4718592   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0208554 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.445    |\n",
      "|    explained_variance   | 0.694     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 17.9      |\n",
      "|    n_updates            | 1740      |\n",
      "|    policy_gradient_loss | -0.013    |\n",
      "|    value_loss           | 30.6      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1080        |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 4398        |\n",
      "|    total_timesteps      | 4751360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019521192 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.421      |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1080       |\n",
      "|    iterations           | 146        |\n",
      "|    time_elapsed         | 4428       |\n",
      "|    total_timesteps      | 4784128    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02306062 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.43      |\n",
      "|    explained_variance   | 0.705      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.66       |\n",
      "|    n_updates            | 1760       |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    value_loss           | 25.6       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1080        |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 4458        |\n",
      "|    total_timesteps      | 4816896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021633413 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.43       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 25.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1080       |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 4487       |\n",
      "|    total_timesteps      | 4849664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02146132 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.431     |\n",
      "|    explained_variance   | 0.643      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.11       |\n",
      "|    n_updates            | 1780       |\n",
      "|    policy_gradient_loss | -0.0122    |\n",
      "|    value_loss           | 26.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1080        |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 4517        |\n",
      "|    total_timesteps      | 4882432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021878928 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.405      |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.07        |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 23.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1080       |\n",
      "|    iterations           | 150        |\n",
      "|    time_elapsed         | 4549       |\n",
      "|    total_timesteps      | 4915200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02147653 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.418     |\n",
      "|    explained_variance   | 0.682      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.1        |\n",
      "|    n_updates            | 1800       |\n",
      "|    policy_gradient_loss | -0.012     |\n",
      "|    value_loss           | 23.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1079        |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 4583        |\n",
      "|    total_timesteps      | 4947968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021558624 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.417      |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 24.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1078        |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 4616        |\n",
      "|    total_timesteps      | 4980736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022605615 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.89        |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1078        |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 4649        |\n",
      "|    total_timesteps      | 5013504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022233205 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.46       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 1830        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 28.6        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load Model and continue training\n",
    "save_dir = \"test_models\"\n",
    "\n",
    "# load the model, and when loading set verbose to 1\n",
    "#loaded_model = MODEL.load(save_dir + f\"/{NAME_MODEL}_{SQUARE_SHAPE}-{T_MOVE}-{T_SHOOT}-{BULL_POS}\", verbose=1)\n",
    "model = MODEL.load(save_dir + f\"/{dir_name}\", verbose=1)\n",
    "\n",
    "# show the save hyperparameters\n",
    "print(\"loaded:\", \"gamma =\", model.gamma, \"n_steps =\", model.n_steps)\n",
    "\n",
    "# as the environment is not serializable, we need to set a new instance of the environment\n",
    "ProtoEnv = gymca.prototypes[1]\n",
    "#total_procs = 16\n",
    "\n",
    "env = DummyVecEnv([make_env(ProtoEnv, i+total_procs) for i in range(total_procs)])\n",
    "\n",
    "\n",
    "model.set_env(env)\n",
    "# and continue training\n",
    "model.learn(5e6)\n",
    "\n",
    "# Save again\n",
    "model.save(save_dir + f\"/{dir_name}\")\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load Model\n",
    "save_dir = \"test_models\"\n",
    "\n",
    "model = MODEL.load(save_dir + dir_name)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "SQUARE_SHAPE = 10\n",
    "T_MOVE = 0.05\n",
    "T_SHOOT = 0.05\n",
    "POS_BULL = [SQUARE_SHAPE-1, SQUARE_SHAPE-1]\n",
    "BULL_POS = f'{SQUARE_SHAPE-1}.{SQUARE_SHAPE-1}'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_15728/1159790100.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     13\u001B[0m                t_any=T_MOVE)\n\u001B[1;32m     14\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m \u001B[0menv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mObservationOneHotWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m \u001B[0menv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mNumTreesReward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0menv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;31m# Load Model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() missing 1 required positional argument: 'shape'"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "\n",
    "# Play\n",
    "ESSAYS = 3\n",
    "train_steps = '7m'\n",
    "\n",
    "ProtoEnv = gymca.prototypes[1]\n",
    "env = ProtoEnv(nrows=SQUARE_SHAPE,\n",
    "               ncols=SQUARE_SHAPE,\n",
    "               pos_bull=POS_BULL,\n",
    "               t_move=T_MOVE,\n",
    "               t_shoot=T_SHOOT,\n",
    "               t_any=T_MOVE)\n",
    "\n",
    "env = ObservationOneHotWrapper(env)\n",
    "env = NumTreesReward(env)\n",
    "# Load Model\n",
    "save_dir = \"modelos_chingones/\"\n",
    "model = MODEL.load(save_dir + MODEL_NAME, env=env)\n",
    "\n",
    "for essay in range(ESSAYS):\n",
    "    total_reward = 0.0\n",
    "    done = False\n",
    "    step = 0\n",
    "    threshold = 15\n",
    "    env.reset()\n",
    "    #env.render()\n",
    "\n",
    "    images = []\n",
    "    obs = env.reset()\n",
    "    img = env.render(rgb=True)\n",
    "\n",
    "    while not done: # and step < threshold:\n",
    "        #print(step)\n",
    "        images.append(img)\n",
    "        action = model.predict(obs, deterministic=True)[0]\n",
    "        #action = env.action_space.sample()  # Your agent goes here!\n",
    "        #action = [1,1] if step % 2  else [3,1]\n",
    "        #print('action', action, type(action))\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        #print(reward)\n",
    "        #print('obs', step)\n",
    "        #print(obs)\n",
    "        #print(obs[1][1])\n",
    "        #print(info)\n",
    "        total_reward += reward\n",
    "        #print(reward)\n",
    "        step += 1\n",
    "        #env.render()\n",
    "        img = env.render(rgb=True)\n",
    "\n",
    "    print('Done', done, step)\n",
    "    print('Total_reward', total_reward)\n",
    "\n",
    "    save_dir_gif = f\"gifs\"\n",
    "    os.makedirs(save_dir_gif, exist_ok=True)\n",
    "\n",
    "    gif_name = save_dir_gif + f\"/{dir_name}\" + f'-{train_steps}' + f\"-{str(essay)}\"\n",
    "    imageio.mimsave(f\"{gif_name}.gif\", images, fps=3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tutorial of Callbacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "\n",
    "class CustomCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    A custom callback that derives from ``BaseCallback``.\n",
    "\n",
    "    :param verbose: Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        # Those variables will be accessible in the callback\n",
    "        # (they are defined in the base class)\n",
    "        # The RL model\n",
    "        # self.model = None  # type: BaseAlgorithm\n",
    "        # An alias for self.model.get_env(), the environment used for training\n",
    "        # self.training_env = None  # type: Union[gym.Env, VecEnv, None]\n",
    "        # Number of time the callback was called\n",
    "        # self.n_calls = 0  # type: int\n",
    "        # num_timesteps is the number of environments multiplied by the number of time env.step() was called\n",
    "        # self.num_timesteps = 0  # type: int\n",
    "        # local and global variables\n",
    "        # self.locals = None  # type: Dict[str, Any]\n",
    "        # self.globals = None  # type: Dict[str, Any]\n",
    "        # The logger object, used to report things in the terminal\n",
    "        # self.logger = None  # stable_baselines3.common.logger\n",
    "        # # Sometimes, for event callback, it is useful\n",
    "        # # to have access to the parent object\n",
    "        # self.parent = None  # type: Optional[BaseCallback]\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        \"\"\"\n",
    "        This method is called before the first rollout starts.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _on_rollout_start(self) -> None:\n",
    "        \"\"\"\n",
    "        A rollout is the collection of environment interaction\n",
    "        using the current policy.\n",
    "        This event is triggered before collecting new samples.\n",
    "        \"\"\"\n",
    "        # For off-policy algorithms like SAC, DDPG, TD3 or DQN, the notion of rollout corresponds to the steps taken in the environment between two updates.\n",
    "        pass\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        \"\"\"\n",
    "        This method will be called by the model after each call to `env.step()`.\n",
    "\n",
    "        For child callback (of an `EventCallback`), this will be called\n",
    "        when the event is triggered.\n",
    "\n",
    "        :return: (bool) If the callback returns False, training is aborted early.\n",
    "        \"\"\"\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        \"\"\"\n",
    "        This event is triggered before updating the policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _on_training_end(self) -> None:\n",
    "        \"\"\"\n",
    "        This event is triggered before exiting the `learn()` method.\n",
    "        \"\"\"\n",
    "        pass\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Optional' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_4224/1844539154.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mclass\u001B[0m \u001B[0mEventCallback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mBaseCallback\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m     \"\"\"\n\u001B[1;32m      3\u001B[0m     \u001B[0mBase\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mtriggering\u001B[0m \u001B[0mcallback\u001B[0m \u001B[0mon\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;34m:\u001B[0m\u001B[0mparam\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mBaseCallback\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0mCallback\u001B[0m \u001B[0mthat\u001B[0m \u001B[0mwill\u001B[0m \u001B[0mbe\u001B[0m \u001B[0mcalled\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_4224/1844539154.py\u001B[0m in \u001B[0;36mEventCallback\u001B[0;34m()\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;34m:\u001B[0m\u001B[0mparam\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mVerbosity\u001B[0m \u001B[0mlevel\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;36m0\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mno\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0minfo\u001B[0m \u001B[0mmessages\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mdebug\u001B[0m \u001B[0mmessages\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \"\"\"\n\u001B[0;32m----> 9\u001B[0;31m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mBaseCallback\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mEventCallback\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallback\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcallback\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Optional' is not defined"
     ]
    }
   ],
   "source": [
    "class EventCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Base class for triggering callback on event.\n",
    "\n",
    "    :param callback: (Optional[BaseCallback]) Callback that will be called\n",
    "        when an event is triggered.\n",
    "    :param verbose: Verbosity level: 0 for no output, 1 for info messages, 2 for debug messages\n",
    "    \"\"\"\n",
    "    def __init__(self, callback: Optional[BaseCallback] = None, verbose: int = 0):\n",
    "        super(EventCallback, self).__init__(verbose=verbose)\n",
    "        self.callback = callback\n",
    "        # Give access to the parent\n",
    "        if callback is not None:\n",
    "            self.callback.parent = self\n",
    "    ...\n",
    "\n",
    "    def _on_event(self) -> bool:\n",
    "        if self.callback is not None:\n",
    "            return self.callback()\n",
    "        return True\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<stable_baselines3.sac.sac.SAC at 0x7f3ad0420580>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "\n",
    "# Save a checkpoint every 1000 steps\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "  save_freq=1000,\n",
    "  save_path=\"./logs/\",\n",
    "  name_prefix=\"rl_model\",\n",
    "  save_replay_buffer=True,\n",
    "  save_vecnormalize=True,\n",
    ")\n",
    "\n",
    "model = SAC(\"MlpPolicy\", \"Pendulum-v1\")\n",
    "model.learn(2000, callback=checkpoint_callback)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bruno/miniconda3/envs/DRL_9/lib/python3.9/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=500, episode_reward=-1572.03 +/- 146.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=1000, episode_reward=-1692.70 +/- 126.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=1500, episode_reward=-1409.64 +/- 83.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2000, episode_reward=-1151.00 +/- 81.34\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2500, episode_reward=-1231.77 +/- 75.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=3000, episode_reward=-260.15 +/- 161.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=3500, episode_reward=-176.87 +/- 60.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=4000, episode_reward=-172.51 +/- 54.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=4500, episode_reward=-222.87 +/- 89.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=5000, episode_reward=-170.71 +/- 60.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n"
     ]
    },
    {
     "data": {
      "text/plain": "<stable_baselines3.sac.sac.SAC at 0x7f3a0044f970>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "# Separate evaluation env\n",
    "eval_env = gym.make(\"Pendulum-v1\")\n",
    "# Use deterministic actions for evaluation\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=\"./logs/\",\n",
    "                             log_path=\"./logs/\", eval_freq=500,\n",
    "                             deterministic=True, render=False)\n",
    "\n",
    "model = SAC(\"MlpPolicy\", \"Pendulum-v1\")\n",
    "model.learn(5000, callback=eval_callback)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=500, episode_reward=-1587.58 +/- 231.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=1000, episode_reward=-1603.03 +/- 153.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=1500, episode_reward=-1498.32 +/- 81.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2000, episode_reward=-1080.34 +/- 101.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2500, episode_reward=-568.68 +/- 69.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=3000, episode_reward=-988.92 +/- 188.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "Eval num_timesteps=3500, episode_reward=-370.21 +/- 356.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=4000, episode_reward=-212.55 +/- 134.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=4500, episode_reward=-124.90 +/- 135.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=5000, episode_reward=-171.00 +/- 56.12\n",
      "Episode length: 200.00 +/- 0.00\n"
     ]
    },
    {
     "data": {
      "text/plain": "<stable_baselines3.sac.sac.SAC at 0x7f3a002bb2e0>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(save_freq=1000, save_path=\"./logs/\")\n",
    "# Separate evaluation env\n",
    "eval_env = gym.make(\"Pendulum-v1\")\n",
    "eval_callback = EvalCallback(eval_env, best_model_save_path=\"./logs/best_model\",\n",
    "                             log_path=\"./logs/results\", eval_freq=500)\n",
    "# Create the callback list\n",
    "callback = CallbackList([checkpoint_callback, eval_callback])\n",
    "\n",
    "model = SAC(\"MlpPolicy\", \"Pendulum-v1\")\n",
    "# Equivalent to:\n",
    "# model.learn(5000, callback=[checkpoint_callback, eval_callback])\n",
    "model.learn(5000, callback=callback)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'Pendulum-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.23e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 133       |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 800       |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 18.9      |\n",
      "|    critic_loss     | 0.231     |\n",
      "|    ent_coef        | 0.812     |\n",
      "|    ent_coef_loss   | -0.331    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 699       |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.4e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 1600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 45.1     |\n",
      "|    critic_loss     | 0.222    |\n",
      "|    ent_coef        | 0.648    |\n",
      "|    ent_coef_loss   | -0.607   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 1499     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.32e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 129       |\n",
      "|    time_elapsed    | 18        |\n",
      "|    total_timesteps | 2400      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 64.6      |\n",
      "|    critic_loss     | 0.337     |\n",
      "|    ent_coef        | 0.532     |\n",
      "|    ent_coef_loss   | -0.618    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 2299      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.2e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 3200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 79.4     |\n",
      "|    critic_loss     | 0.445    |\n",
      "|    ent_coef        | 0.455    |\n",
      "|    ent_coef_loss   | -0.478   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1e+03   |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 79.5     |\n",
      "|    critic_loss     | 0.74     |\n",
      "|    ent_coef        | 0.395    |\n",
      "|    ent_coef_loss   | -0.357   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 3899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -856     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 76.4     |\n",
      "|    critic_loss     | 1.04     |\n",
      "|    ent_coef        | 0.336    |\n",
      "|    ent_coef_loss   | -0.478   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -766     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 75.4     |\n",
      "|    critic_loss     | 1.93     |\n",
      "|    ent_coef        | 0.283    |\n",
      "|    ent_coef_loss   | -0.635   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 5499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -682     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 6400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 74.4     |\n",
      "|    critic_loss     | 1.52     |\n",
      "|    ent_coef        | 0.233    |\n",
      "|    ent_coef_loss   | -0.565   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 6299     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -630     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 74.2     |\n",
      "|    critic_loss     | 2.28     |\n",
      "|    ent_coef        | 0.196    |\n",
      "|    ent_coef_loss   | -0.658   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -585     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 69.7     |\n",
      "|    critic_loss     | 2.13     |\n",
      "|    ent_coef        | 0.169    |\n",
      "|    ent_coef_loss   | -0.177   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -544     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 8800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 59.5     |\n",
      "|    critic_loss     | 2.35     |\n",
      "|    ent_coef        | 0.149    |\n",
      "|    ent_coef_loss   | -0.361   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8699     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -514     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 76       |\n",
      "|    total_timesteps | 9600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 59.5     |\n",
      "|    critic_loss     | 3        |\n",
      "|    ent_coef        | 0.131    |\n",
      "|    ent_coef_loss   | -0.433   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9499     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-118.42 +/- 75.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 200      |\n",
      "|    mean_reward     | -118     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 51.5     |\n",
      "|    critic_loss     | 2.52     |\n",
      "|    ent_coef        | 0.122    |\n",
      "|    ent_coef_loss   | -0.37    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 9899     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "Stopping training because the mean reward -118.42  is above the threshold -200\n"
     ]
    },
    {
     "data": {
      "text/plain": "<stable_baselines3.sac.sac.SAC at 0x7f3a00243910>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stop training in reward threshold\n",
    "import gym\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "\n",
    "# Separate evaluation env\n",
    "eval_env = gym.make(\"Pendulum-v1\")\n",
    "# Stop training when the model reaches the reward threshold\n",
    "callback_on_best = StopTrainingOnRewardThreshold(reward_threshold=-200, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, callback_on_new_best=callback_on_best, verbose=1)\n",
    "\n",
    "model = SAC(\"MlpPolicy\", \"Pendulum-v1\", verbose=1)\n",
    "# Almost infinite number of timesteps, but the training will stop\n",
    "# early as soon as the reward threshold is reached\n",
    "model.learn(int(1e10), callback=eval_callback)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'Pendulum-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.23e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 976       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 2         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.23e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 812          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021034377 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.00681      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.57e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.000935    |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 9.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.26e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 771          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013219048 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.116        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.62e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.000198    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 8.79e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | -1.23e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 752           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 10            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060802046 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 0.1           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.02e+03      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000272     |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 9.12e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.22e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 742          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033350592 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.09e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 8.73e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 200           |\n",
      "|    ep_rew_mean          | -1.22e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 735           |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 16            |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044205948 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | 0.0134        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.46e+03      |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.000128     |\n",
      "|    std                  | 0.999         |\n",
      "|    value_loss           | 7.4e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.23e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 722          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011907861 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.00643      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.63e+03     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 7.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.23e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 686          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029609622 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0.0021       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.64e+03     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 8.99e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.22e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 679          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014420296 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 0.0026       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.65e+03     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.000517    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 8.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 200          |\n",
      "|    ep_rew_mean          | -1.2e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 677          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049468246 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0.00197      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.74e+03     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.02e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "<stable_baselines3.ppo.ppo.PPO at 0x7f3a0021fdc0>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EveryNTimesteps\n",
    "\n",
    "# this is equivalent to defining CheckpointCallback(save_freq=500)\n",
    "# checkpoint_callback will be triggered every 500 steps\n",
    "checkpoint_on_event = CheckpointCallback(save_freq=1, save_path=\"./logs/\")\n",
    "event_callback = EveryNTimesteps(n_steps=500, callback=checkpoint_on_event)\n",
    "\n",
    "model = PPO(\"MlpPolicy\", \"Pendulum-v1\", verbose=1)\n",
    "\n",
    "model.learn(int(2e4), callback=event_callback)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'Pendulum-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 200       |\n",
      "|    ep_rew_mean        | -1.27e+03 |\n",
      "| time/                 |           |\n",
      "|    fps                | 413       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -1.45     |\n",
      "|    explained_variance | 0.0651    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -50.4     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.23e+03  |\n",
      "-------------------------------------\n",
      "Stopping training with a total of 1000 steps because the A2C model reached max_episodes=5, by playing for 5 episodes \n"
     ]
    },
    {
     "data": {
      "text/plain": "<stable_baselines3.a2c.a2c.A2C at 0x7f3a0044fc70>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.callbacks import StopTrainingOnMaxEpisodes\n",
    "\n",
    "# Stops training when the model reaches the maximum number of episodes\n",
    "callback_max_episodes = StopTrainingOnMaxEpisodes(max_episodes=5, verbose=1)\n",
    "\n",
    "model = A2C(\"MlpPolicy\", \"Pendulum-v1\", verbose=1)\n",
    "# Almost infinite number of timesteps, but the training will stop\n",
    "# early as soon as the max number of episodes is reached\n",
    "model.learn(int(1e10), callback=callback_max_episodes)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'Pendulum-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.6e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 122      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 800      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 28.5     |\n",
      "|    critic_loss     | 0.0484   |\n",
      "|    ent_coef        | 0.503    |\n",
      "|    ent_coef_loss   | -1.06    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 699      |\n",
      "---------------------------------\n",
      "Eval num_timesteps=1000, episode_reward=-1732.38 +/- 46.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/              |           |\n",
      "|    mean_ep_length  | 200       |\n",
      "|    mean_reward     | -1.73e+03 |\n",
      "| time/              |           |\n",
      "|    total_timesteps | 1000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 36        |\n",
      "|    critic_loss     | 0.0323    |\n",
      "|    ent_coef        | 0.417     |\n",
      "|    ent_coef_loss   | -1.21     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 899       |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.54e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 116       |\n",
      "|    time_elapsed    | 13        |\n",
      "|    total_timesteps | 1600      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 54.9      |\n",
      "|    critic_loss     | 0.0491    |\n",
      "|    ent_coef        | 0.26      |\n",
      "|    ent_coef_loss   | -0.984    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1499      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=2000, episode_reward=-1026.74 +/- 46.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------\n",
      "| eval/              |           |\n",
      "|    mean_ep_length  | 200       |\n",
      "|    mean_reward     | -1.03e+03 |\n",
      "| time/              |           |\n",
      "|    total_timesteps | 2000      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 66.7      |\n",
      "|    critic_loss     | 0.103     |\n",
      "|    ent_coef        | 0.221     |\n",
      "|    ent_coef_loss   | -0.287    |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 1899      |\n",
      "----------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -1.4e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 114      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 2400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 71.8     |\n",
      "|    critic_loss     | 0.258    |\n",
      "|    ent_coef        | 0.214    |\n",
      "|    ent_coef_loss   | -0.0304  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2299     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=3000, episode_reward=-454.78 +/- 68.20\n",
      "Episode length: 200.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 200      |\n",
      "|    mean_reward     | -455     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 3000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 83.7     |\n",
      "|    critic_loss     | 0.257    |\n",
      "|    ent_coef        | 0.232    |\n",
      "|    ent_coef_loss   | 0.339    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2899     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 200       |\n",
      "|    ep_rew_mean     | -1.21e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 112       |\n",
      "|    time_elapsed    | 28        |\n",
      "|    total_timesteps | 3200      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 83.6      |\n",
      "|    critic_loss     | 0.305     |\n",
      "|    ent_coef        | 0.24      |\n",
      "|    ent_coef_loss   | 0.219     |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 3099      |\n",
      "----------------------------------\n",
      "Eval num_timesteps=4000, episode_reward=-612.13 +/- 597.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 200      |\n",
      "|    mean_reward     | -612     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 4000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 88.1     |\n",
      "|    critic_loss     | 0.623    |\n",
      "|    ent_coef        | 0.234    |\n",
      "|    ent_coef_loss   | -0.318   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -994     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 109      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 4000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -914     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 111      |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 4800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 85.2     |\n",
      "|    critic_loss     | 1.07     |\n",
      "|    ent_coef        | 0.191    |\n",
      "|    ent_coef_loss   | -0.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4699     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=5000, episode_reward=-150.56 +/- 55.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 200      |\n",
      "|    mean_reward     | -151     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 5000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 83.4     |\n",
      "|    critic_loss     | 1.97     |\n",
      "|    ent_coef        | 0.182    |\n",
      "|    ent_coef_loss   | 0.152    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4899     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -810     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 111      |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 5600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 85.8     |\n",
      "|    critic_loss     | 3.78     |\n",
      "|    ent_coef        | 0.165    |\n",
      "|    ent_coef_loss   | 0.224    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5499     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=6000, episode_reward=-210.88 +/- 71.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 200      |\n",
      "|    mean_reward     | -211     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 6000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 73.8     |\n",
      "|    critic_loss     | 3.28     |\n",
      "|    ent_coef        | 0.162    |\n",
      "|    ent_coef_loss   | -0.0659  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -739     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 111      |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 6400     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 81.5     |\n",
      "|    critic_loss     | 4.31     |\n",
      "|    ent_coef        | 0.158    |\n",
      "|    ent_coef_loss   | -0.105   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6299     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=7000, episode_reward=-100.32 +/- 48.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 200      |\n",
      "|    mean_reward     | -100     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 7000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 77.3     |\n",
      "|    critic_loss     | 2.84     |\n",
      "|    ent_coef        | 0.146    |\n",
      "|    ent_coef_loss   | -0.0151  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6899     |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -670     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 111      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 72.5     |\n",
      "|    critic_loss     | 2.56     |\n",
      "|    ent_coef        | 0.142    |\n",
      "|    ent_coef_loss   | -0.378   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=8000, episode_reward=-193.29 +/- 94.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 200      |\n",
      "|    mean_reward     | -193     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 8000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 76.8     |\n",
      "|    critic_loss     | 2.52     |\n",
      "|    ent_coef        | 0.135    |\n",
      "|    ent_coef_loss   | -0.0539  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -616     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 111      |\n",
      "|    time_elapsed    | 71       |\n",
      "|    total_timesteps | 8000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -572     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 112      |\n",
      "|    time_elapsed    | 78       |\n",
      "|    total_timesteps | 8800     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 79.2     |\n",
      "|    critic_loss     | 3.88     |\n",
      "|    ent_coef        | 0.119    |\n",
      "|    ent_coef_loss   | 0.00251  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8699     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=9000, episode_reward=-126.88 +/- 4.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 200      |\n",
      "|    mean_reward     | -127     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 9000     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 74.2     |\n",
      "|    critic_loss     | 2.29     |\n",
      "|    ent_coef        | 0.116    |\n",
      "|    ent_coef_loss   | 0.137    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -540     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 111      |\n",
      "|    time_elapsed    | 85       |\n",
      "|    total_timesteps | 9600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 73.9     |\n",
      "|    critic_loss     | 2.52     |\n",
      "|    ent_coef        | 0.116    |\n",
      "|    ent_coef_loss   | 0.164    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9499     |\n",
      "---------------------------------\n",
      "Eval num_timesteps=10000, episode_reward=-168.89 +/- 54.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 200      |\n",
      "|    mean_reward     | -169     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 10000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 63.2     |\n",
      "|    critic_loss     | 2.25     |\n",
      "|    ent_coef        | 0.108    |\n",
      "|    ent_coef_loss   | -0.118   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9899     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | -511     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 110      |\n",
      "|    time_elapsed    | 93       |\n",
      "|    total_timesteps | 10400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 69.6     |\n",
      "|    critic_loss     | 2.07     |\n",
      "|    ent_coef        | 0.103    |\n",
      "|    ent_coef_loss   | -0.0513  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10299    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=11000, episode_reward=-171.60 +/- 52.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 200      |\n",
      "|    mean_reward     | -172     |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 11000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 65.6     |\n",
      "|    critic_loss     | 4.21     |\n",
      "|    ent_coef        | 0.104    |\n",
      "|    ent_coef_loss   | -0.0193  |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10899    |\n",
      "---------------------------------\n",
      "Stopping training because there was no new best model in the last 4 evaluations\n"
     ]
    },
    {
     "data": {
      "text/plain": "<stable_baselines3.sac.sac.SAC at 0x7f3a00243460>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "\n",
    "# Separate evaluation env\n",
    "eval_env = gym.make(\"Pendulum-v1\")\n",
    "# Stop training if there is no improvement after more than 3 evaluations\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(eval_env, eval_freq=1000, callback_after_eval=stop_train_callback, verbose=1)\n",
    "\n",
    "model = SAC(\"MlpPolicy\", \"Pendulum-v1\", learning_rate=1e-3, verbose=1)\n",
    "# Almost infinite number of timesteps, but the training will stop early\n",
    "# as soon as the number of consecutive evaluations without model\n",
    "# improvement is greater than 3\n",
    "model.learn(int(1e10), callback=eval_callback)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666804041663757, max=1.0)",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa35f1ec5e174bc4867651e08b880198"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.14.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/bruno/Documents/Firefighter_RL/Ema_envs/wandb/run-20230317_165856-7bzczhxp</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/brunogupa/sb3/runs/7bzczhxp' target=\"_blank\">absurd-durian-1</a></strong> to <a href='https://wandb.ai/brunogupa/sb3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/brunogupa/sb3' target=\"_blank\">https://wandb.ai/brunogupa/sb3</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/brunogupa/sb3/runs/7bzczhxp' target=\"_blank\">https://wandb.ai/brunogupa/sb3/runs/7bzczhxp</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'CartPole-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to runs/7bzczhxp/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23       |\n",
      "|    ep_rew_mean     | 23       |\n",
      "| time/              |          |\n",
      "|    fps             | 1046     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 29.6        |\n",
      "|    ep_rew_mean          | 29.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 852         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009045091 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.00281     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.28        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 55.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.7        |\n",
      "|    ep_rew_mean          | 34.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 814         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 7           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009601954 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.0395      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.6        |\n",
      "|    ep_rew_mean          | 44.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 779         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010649152 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.639      |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22          |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0266     |\n",
      "|    value_loss           | 51.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 57.4        |\n",
      "|    ep_rew_mean          | 57.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 761         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012958449 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.604      |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 74.2         |\n",
      "|    ep_rew_mean          | 74.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 752          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 16           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071314545 |\n",
      "|    clip_fraction        | 0.0483       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.582       |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.1         |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    value_loss           | 70.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 90.1        |\n",
      "|    ep_rew_mean          | 90.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 744         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012315268 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.584      |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 43.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 105          |\n",
      "|    ep_rew_mean          | 105          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 733          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062353755 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00904     |\n",
      "|    value_loss           | 46.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 123          |\n",
      "|    ep_rew_mean          | 123          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 728          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052392976 |\n",
      "|    clip_fraction        | 0.0464       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.582       |\n",
      "|    explained_variance   | 0.885        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.76         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00768     |\n",
      "|    value_loss           | 24.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 140         |\n",
      "|    ep_rew_mean          | 140         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009336078 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.564      |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    value_loss           | 40.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 154          |\n",
      "|    ep_rew_mean          | 154          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 721          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 31           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055190534 |\n",
      "|    clip_fraction        | 0.075        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.82         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 27.2         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 171        |\n",
      "|    ep_rew_mean          | 171        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 716        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00799763 |\n",
      "|    clip_fraction        | 0.0919     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.565     |\n",
      "|    explained_variance   | 0.908      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.86       |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.00894   |\n",
      "|    value_loss           | 17         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 192         |\n",
      "|    ep_rew_mean          | 192         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002150923 |\n",
      "|    clip_fraction        | 0.00713     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.55       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td></td></tr><tr><td>rollout/ep_len_mean</td><td></td></tr><tr><td>rollout/ep_rew_mean</td><td></td></tr><tr><td>time/fps</td><td></td></tr><tr><td>train/approx_kl</td><td></td></tr><tr><td>train/clip_fraction</td><td></td></tr><tr><td>train/clip_range</td><td></td></tr><tr><td>train/entropy_loss</td><td></td></tr><tr><td>train/explained_variance</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/policy_gradient_loss</td><td></td></tr><tr><td>train/value_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>26624</td></tr><tr><td>rollout/ep_len_mean</td><td>191.75</td></tr><tr><td>rollout/ep_rew_mean</td><td>191.75</td></tr><tr><td>time/fps</td><td>714.0</td></tr><tr><td>train/approx_kl</td><td>0.00215</td></tr><tr><td>train/clip_fraction</td><td>0.00713</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>-0.55045</td></tr><tr><td>train/explained_variance</td><td>0.66111</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr><tr><td>train/loss</td><td>30.47888</td></tr><tr><td>train/policy_gradient_loss</td><td>-0.00262</td></tr><tr><td>train/value_loss</td><td>35.80344</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">absurd-durian-1</strong> at: <a href='https://wandb.ai/brunogupa/sb3/runs/7bzczhxp' target=\"_blank\">https://wandb.ai/brunogupa/sb3/runs/7bzczhxp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20230317_165856-7bzczhxp/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "config = {\n",
    "    \"policy_type\": \"MlpPolicy\",\n",
    "    \"total_timesteps\": 25000,\n",
    "    \"env_id\": \"CartPole-v1\",\n",
    "}\n",
    "run = wandb.init(\n",
    "    project=\"sb3\",\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "    # monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
    "    # save_code=True,  # optional\n",
    ")\n",
    "\n",
    "model = PPO(config[\"policy_type\"], config[\"env_id\"], verbose=1, tensorboard_log=f\"runs/{run.id}\")\n",
    "model.learn(\n",
    "    total_timesteps=config[\"total_timesteps\"],\n",
    "    callback=WandbCallback(\n",
    "        model_save_path=f\"models/{run.id}\",\n",
    "        verbose=2,\n",
    "    ),\n",
    ")\n",
    "run.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mbrunogupa\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.14.0"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/bruno/Documents/Firefighter_RL/Ema_envs/wandb/run-20230317_165419-w7yca8zf</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/brunogupa/my-awesome-project/runs/w7yca8zf' target=\"_blank\">chocolate-moon-1</a></strong> to <a href='https://wandb.ai/brunogupa/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/brunogupa/my-awesome-project' target=\"_blank\">https://wandb.ai/brunogupa/my-awesome-project</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/brunogupa/my-awesome-project/runs/w7yca8zf' target=\"_blank\">https://wandb.ai/brunogupa/my-awesome-project/runs/w7yca8zf</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.79167</td></tr><tr><td>loss</td><td>0.1838</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">chocolate-moon-1</strong> at: <a href='https://wandb.ai/brunogupa/my-awesome-project/runs/w7yca8zf' target=\"_blank\">https://wandb.ai/brunogupa/my-awesome-project/runs/w7yca8zf</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20230317_165419-w7yca8zf/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"my-awesome-project\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"architecture\": \"CNN\",\n",
    "    \"dataset\": \"CIFAR-100\",\n",
    "    \"epochs\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# simulate training\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2 ** -epoch - random.random() / epoch - offset\n",
    "    loss = 2 ** -epoch + random.random() / epoch + offset\n",
    "\n",
    "    # log metrics to wandb\n",
    "    wandb.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# [optional] finish the wandb run, necessary in notebooks\n",
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
